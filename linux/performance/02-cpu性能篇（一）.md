## 一、平均负载（ Load Average）

**平均负载概念**

平均负载是指单位时间内，系统处于**可运行状态**和**不可中断状态**的平均进程数，也就是**平均活跃进程数**，它和 CPU 使用率并没有直接关系。

* **可运行状态：**是指正在使用 CPU 或者正在等待 CPU 的进程。用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。

* **不可中断状态**：的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，用 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。

* **平均活跃进程数**，直观上的理解就是单位时间内的活跃进程数

> 情形一：
>
> prod@QQ-BJ-test-wj01:~$ uptime 
>  09:35:56 up 268 days, 23:13,  2 users,  load average: 0.13, 0.08, 0.02
>
> 情形二：
>
> laoqiu@autumn-Air  ~  uptime
>  9:37  up 2 days, 15:51, 3 users, load averages: 1.18 1.37 1.62
>
> 现象说明：比如当平均负载为 2 时，意味着什么呢？
>
> * 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。
> * 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。
> * 而在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。



**平均负载的合理范围**

* 查看cpu内核数：

  > $ grep 'model name' /proc/cpuinfo | wc -l2
  >
  > 2

  当平均负载比 CPU 个数还大的时候，系统已经出现了过载。

* 一般情况下，**当平均负载高于 CPU 数量 70% 的时候**，就应该分析排查负载高的问题了。

**平均负载小结**

平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，并不能直接发现到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：

* 平均负载高有可能是 CPU 密集型进程导致的；
* 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了；
* 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。

## 二、CPU上下文切换

### **1. 什么是CPU上下文**

Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好**CPU 寄存器**和**程序计数器（Program Counter，PC）。**

**就是说在执行每个任务之前，操作系统都需要重新设置下CPU寄存器和程序计数器**

**CPU 寄存器**，是 CPU 内置的容量小、但速度极快的内存。而**程序计数器**，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做**CPU 上下文。**

### **2. 什么是CPU上下文的切换**

CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

### **3. cpu上下文切换的种类**

根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，包括**进程上下文切换**、**线程上下文切换**以及**中断上下文切换**。

不管是哪种场景导致的上下文切换，都应该知道：

1. CPU 上下文切换，是保证 Linux 系统正常工作的核心功能之一，一般情况下不需要我们特别关注。
2. **过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能大幅下降。**

### 4. 如何查看上下文切换情况

* **vmstat**

  vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。

  ```shell
  # 每隔5秒输出1组数据
  $ vmstat 5
  procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
   r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
   0  0      0 7005360  91564 818900    0    0     0     0   25   33  0  0 100  0  0
  ```

  * r（Running or Runnable）：就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
  * b（Blocked）：处于不可中断睡眠状态的进程数。
  * cs（context switch）：每秒上下文切换的次数。
  * in（interrupt）：每秒中断的次数。

* **pidstat**

  vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，使用**pidstat**加上 -w 选项，可以查看每个进程上下文切换的情况了。

  ```shell
  # 每隔5秒输出1组数据
  $ pidstat -w 5
  Linux 4.15.0 (ubuntu)  09/23/18  _x86_64_  (2 CPU)
  
  08:18:26      UID       PID   cswch/s nvcswch/s  Command
  08:18:31        0         1      0.20      0.00  systemd
  08:18:31        0         8      5.40      0.00  rcu_sched
  ...
  ```

  * **cswch** ，表示每秒自愿上下文切换（voluntary context switches）的次数。所谓**自愿上下文切换**，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
  * **nvcswch** ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。**非自愿上下文切换**，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

### 5. 案例操作

​	目标：sysbench 来模拟系统多线程调度切换的情况。使用pidstat和vmstat查看性能。

 1. 首先，在第一个终端里运行 sysbench ，模拟系统多线程调度的瓶颈：

    ```shell
    # 以10个线程运行5分钟的基准测试，模拟多线程切换的问题
    $ sysbench --threads=10 --max-time=300 threads run
    ```

    

2. 在第二个终端运行 vmstat ，观察系统上下文切换情况：

   ```shell
   # 每隔1秒输出1组数据（需要Ctrl+C才结束）
   $ vmstat 1
   procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
    r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
    6  0      0 6487428 118240 1292772    0    0     0     0 9019 1398830 16 84  0  0  0
    8  0      0 6487428 118240 1292772    0    0     0     0 10191 1392312 16 84  0  0  0
   ```

   数据分析：

   * r 列：就绪队列的长度已经到了 8，远远超过了系统 CPU 的个数 2，所以肯定会有大量的 CPU 竞争。

   * us（user）和 sy（system）列：这两列的 CPU 使用率加起来上升到了 100%，其中系统 CPU 使用率，也就是 sy 列高达 84%，说明 CPU 主要是被内核占用了。

   * in 列：中断次数也上升到了 1 万左右，说明中断处理也是个潜在的问题。

     > 中断发生的类型可以从/proc/interrupts 这个只读文件中读取。

3. 在第三个终端再用 pidstat 来看一下进程CPU 和进程上下文切换的情况：

   ```shell
   # 每隔1秒输出1组数据（需要 Ctrl+C 才结束）
   # -w参数表示输出进程切换指标，而-u参数则表示输出CPU使用指标
   $ pidstat -w -u 1
   08:06:33      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
   08:06:34        0     10488   30.00  100.00    0.00    0.00  100.00     0  sysbench
   08:06:34        0     26326    0.00    1.00    0.00    0.00    1.00     0  kworker/u4:2
   
   08:06:33      UID       PID   cswch/s nvcswch/s  Command
   08:06:34        0         8     11.00      0.00  rcu_sched
   08:06:34        0        16      1.00      0.00  ksoftirqd/1
   08:06:34        0       471      1.00      0.00  hv_balloon
   08:06:34        0      1230      1.00      0.00  iscsid
   08:06:34        0      4089      1.00      0.00  kworker/1:5
   08:06:34        0      4333      1.00      0.00  kworker/0:3
   08:06:34        0     10499      1.00    224.00  pidstat
   08:06:34        0     26326    236.00      0.00  kworker/u4:2
   08:06:34     1000     26784    223.00      0.00  sshd
   ```

   数据分析：

   * CPU 使用率的升高是 sysbench 导致的，

   * 上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 pidstat ，以及自愿上下文切换频率最高的内核线程 kworker 和 sshd。

   * 问题：pidstat 输出的上下文切换次数，加起来也就几百，比 vmstat 的 139 万明显小了太多？

     原因：pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。

     ```shell
     
     # 每隔1秒输出一组数据（需要 Ctrl+C 才结束）
     # -wt 参数表示输出线程的上下文切换指标
     $ pidstat -wt 1
     08:14:05      UID      TGID       TID   cswch/s nvcswch/s  Command
     ...
     08:14:05        0     10551         -      6.00      0.00  sysbench
     08:14:05        0         -     10551      6.00      0.00  |__sysbench
     08:14:05        0         -     10552  18911.00 103740.00  |__sysbench
     08:14:05        0         -     10553  18915.00 100955.00  |__sysbench
     08:14:05        0         -     10554  18827.00 103954.00  |__sysbench
     ...
     ```

4. 案例总结：
   * 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；
   * 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；
   * 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。

## 三、cpu使用率

**CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时间的百分比**



通过 top、ps、pidstat 等工具能够轻松找到 CPU 使用率较高（比如 100% ）的进程。接下来就需要进一步知道占用 CPU 的到底是代码里的哪个函数：

* GDB（The GNU Project Debugger）：GDB 在调试程序错误方面很强大，但并不适合在性能分析的早期应用。

* **perf**：perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。
  * perf top：它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数

CPU 使用率过高的问题后，使用 top 等工具找出异常的进程，利用 perf 找出引发性能问题的函数。



系统的 CPU 使用率，不仅包括进程用户态和内核态的运行，还包括中断处理、等待 I/O 以及内核线程等。所以，当你发现系统的 CPU 使用率很高的时候，不一定能找到相对应的高 CPU 使用率的进程。



> 碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，有可能是下面这两种情况。
>
> 1. 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。
> 2. 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。
>
> 对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。